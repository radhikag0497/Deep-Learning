{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating Faces using StyleGAN2-ada.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d2b9009445846f9a4ab7de845d2721f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f26710e2d35e4584990a65466e35ea30",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c0e61e20b2da448a946c62516ab6169d",
              "IPY_MODEL_e57a2506487a42e68d14cb954184556c"
            ]
          }
        },
        "f26710e2d35e4584990a65466e35ea30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0e61e20b2da448a946c62516ab6169d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fd7c425ec6b04d888f74581161de04f1",
            "_dom_classes": [],
            "description": "Seed 1000: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54716bde643b43adbe80a8cae0b5b1cc"
          }
        },
        "e57a2506487a42e68d14cb954184556c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2b2fe2cb5d8432fbaee6df1ff293a8e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [01:03&lt;00:00,  1.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46e9015c7bda4079bc7779bd8aeeaa51"
          }
        },
        "fd7c425ec6b04d888f74581161de04f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54716bde643b43adbe80a8cae0b5b1cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2b2fe2cb5d8432fbaee6df1ff293a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46e9015c7bda4079bc7779bd8aeeaa51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6652e56ccb644972bfc561d1d66ac96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8cb0387b6adb4b909feecba7df8de4fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0db9168525c449ada302a5b322fdf2c7",
              "IPY_MODEL_7a690864aaaa458cba99bfa74e8aa688"
            ]
          }
        },
        "8cb0387b6adb4b909feecba7df8de4fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0db9168525c449ada302a5b322fdf2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a00f7a43aa194e2e8e07b4256f71c959",
            "_dom_classes": [],
            "description": "Seed 1003: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_549ce442b2034d0db29e6b58a4e591c2"
          }
        },
        "7a690864aaaa458cba99bfa74e8aa688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_274c867186be4d75bfb9f6d838eeacd5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [02:37&lt;00:00,  1.58s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa7bc07ebdf14c96bc3a1595e08a2b92"
          }
        },
        "a00f7a43aa194e2e8e07b4256f71c959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "549ce442b2034d0db29e6b58a4e591c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "274c867186be4d75bfb9f6d838eeacd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa7bc07ebdf14c96bc3a1595e08a2b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0mKBUtNc6q6"
      },
      "source": [
        "# Generating High Rez GAN Faces \r\n",
        "This notebook demonstrates how to run NVidia StyleGAN2 ADA inside of a Google CoLab notebook. I suggest you use this to generate GAN faces from a pretrained model. If you try to train your own, you will run into compute limitations of Google CoLab. Make sure to run this code on a GPU instance. GPU is assumed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVbUEjID0S9x",
        "outputId": "cf257da1-0392-4e02-ad3a-f2e7d0ba2752"
      },
      "source": [
        "# Run this for Google CoLab (use TensorFlow 1.x)\r\n",
        "%tensorflow_version 1.x\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bsTLoLX0cCQ"
      },
      "source": [
        "Next, clone StyleGAN2 ADA from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eef7b1Ry0Yei",
        "outputId": "15895978-a995-4bb9-c59a-47841460e373"
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan2-ada'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Total 71 (delta 0), reused 0 (delta 0), pack-reused 71\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FREzias40lPJ"
      },
      "source": [
        "Verify that StyleGAN has been cloned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA5Hi3Ke0e7n",
        "outputId": "32a5410d-6426-4c4b-e2dd-0d85f1541e4d"
      },
      "source": [
        "!ls /content/stylegan2-ada/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calc_metrics.py  Dockerfile   LICENSE.txt   README.md\t     train.py\n",
            "dataset_tool.py  docs\t      metrics\t    style_mixing.py\n",
            "dnnlib\t\t generate.py  projector.py  training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmE-sm3R0rVA"
      },
      "source": [
        "# Run StyleGan2 From Command Line\r\n",
        "\r\n",
        "Add the StyleGAN folder to Python so that you can import it. The code below is based on code from NVidia. This actually generates your images. When you use StyleGAN you will generally create a GAN from a seed number, such as 6600. GANs are actually created by a latent vector, containing 512 floating point values. The seed is used by the GAN code to generate these 512 values. The seed value is easier to represent in code than a 512 value vector. However, while a small change to the latent vector results in a small change to the image, even a small change to the seed value will produce a radically different image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldbW3qVs0tVo",
        "outputId": "623ecee6-4858-4a80-e01c-2079008285f8"
      },
      "source": [
        "!python /content/stylegan2-ada/generate.py \\\r\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl \\\r\n",
        "  --outdir=/content/results --seeds=6600-6625 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\"...\n",
            "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl ... done\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
            "Generating image for seed 6600 (0/26) ...\n",
            "Generating image for seed 6601 (1/26) ...\n",
            "Generating image for seed 6602 (2/26) ...\n",
            "Generating image for seed 6603 (3/26) ...\n",
            "Generating image for seed 6604 (4/26) ...\n",
            "Generating image for seed 6605 (5/26) ...\n",
            "Generating image for seed 6606 (6/26) ...\n",
            "Generating image for seed 6607 (7/26) ...\n",
            "Generating image for seed 6608 (8/26) ...\n",
            "Generating image for seed 6609 (9/26) ...\n",
            "Generating image for seed 6610 (10/26) ...\n",
            "Generating image for seed 6611 (11/26) ...\n",
            "Generating image for seed 6612 (12/26) ...\n",
            "Generating image for seed 6613 (13/26) ...\n",
            "Generating image for seed 6614 (14/26) ...\n",
            "Generating image for seed 6615 (15/26) ...\n",
            "Generating image for seed 6616 (16/26) ...\n",
            "Generating image for seed 6617 (17/26) ...\n",
            "Generating image for seed 6618 (18/26) ...\n",
            "Generating image for seed 6619 (19/26) ...\n",
            "Generating image for seed 6620 (20/26) ...\n",
            "Generating image for seed 6621 (21/26) ...\n",
            "Generating image for seed 6622 (22/26) ...\n",
            "Generating image for seed 6623 (23/26) ...\n",
            "Generating image for seed 6624 (24/26) ...\n",
            "Generating image for seed 6625 (25/26) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FTrTtBs072c",
        "outputId": "3cc1b9ab-4110-46e5-b84f-19da2b33258c"
      },
      "source": [
        "!ls /content/results/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed6600.png  seed6606.png  seed6612.png  seed6618.png\tseed6624.png\n",
            "seed6601.png  seed6607.png  seed6613.png  seed6619.png\tseed6625.png\n",
            "seed6602.png  seed6608.png  seed6614.png  seed6620.png\n",
            "seed6603.png  seed6609.png  seed6615.png  seed6621.png\n",
            "seed6604.png  seed6610.png  seed6616.png  seed6622.png\n",
            "seed6605.png  seed6611.png  seed6617.png  seed6623.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmLonTyQ1Gbg"
      },
      "source": [
        "Next, copy the images to a folder of your choice on GDrive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNBEM7lo0_dn"
      },
      "source": [
        "cp /content/results/* \\\r\n",
        "    /content/drive/My\\ Drive/projects/stylegan2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RemH9AIi3C43"
      },
      "source": [
        "# Run StyleGAN2 From Python Code\r\n",
        "Add the StyleGAN2 folder to Python so that you can import it. The code below is based on code from NVIDIA. This actually generates your images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG6ZghGa3Nk3"
      },
      "source": [
        "import sys\r\n",
        "import pickle\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import PIL.Image\r\n",
        "from IPython.display import Image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "sys.path.insert(0, \"/content/stylegan2-ada\")\r\n",
        "\r\n",
        "import dnnlib\r\n",
        "import dnnlib.tflib as tflib\r\n",
        "\r\n",
        "def seed2vec(Gs, seed):\r\n",
        "  rnd = np.random.RandomState(seed)\r\n",
        "  return rnd.randn(1, *Gs.input_shape[1:])\r\n",
        "\r\n",
        "def init_random_state(Gs, seed):\r\n",
        "  rnd = np.random.RandomState(seed) \r\n",
        "  noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\r\n",
        "  tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\r\n",
        "\r\n",
        "def display_image(image):\r\n",
        "  plt.axis('off')\r\n",
        "  plt.imshow(image)\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "def generate_image(Gs, z, truncation_psi):\r\n",
        "    # Render images for dlatents initialized from random seeds.\r\n",
        "    Gs_kwargs = {\r\n",
        "        'output_transform': dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True),\r\n",
        "        'randomize_noise': False\r\n",
        "    }\r\n",
        "    if truncation_psi is not None:\r\n",
        "        Gs_kwargs['truncation_psi'] = truncation_psi\r\n",
        "\r\n",
        "    label = np.zeros([1] + Gs.input_shapes[1][1:])\r\n",
        "    images = Gs.run(z, label, **Gs_kwargs) # [minibatch, height, width, channel]\r\n",
        "    return images[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00TfF7bx3T63",
        "outputId": "45aafcf8-4617-4ff4-de5a-678a85f0893b"
      },
      "source": [
        "import IPython.display\r\n",
        "\r\n",
        "URL = \"https://github.com/jeffheaton/pretrained-gan-fish/releases/download/1.0.0/fish-gan-2020-12-09.pkl\"\r\n",
        "# URL = \"https://github.com/jeffheaton/pretrained-merry-gan-mas/releases/download/v1/christmas-gan-2020-12-03.pkl\"\r\n",
        "# URL = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\"\r\n",
        "tflib.init_tf()\r\n",
        "print('Loading networks from \"%s\"...' % URL)\r\n",
        "with dnnlib.util.open_url(URL) as fp:\r\n",
        "    _G, _D, Gs = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\"...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELN0mZWf3UlY"
      },
      "source": [
        "# Choose your own starting and ending seed.\r\n",
        "SEED_FROM = 1003\r\n",
        "SEED_TO = 1006\r\n",
        "\r\n",
        "# Generate the images for the seeds.\r\n",
        "for i in range(SEED_FROM, SEED_TO):\r\n",
        "  print(f\"Seed {i}\")\r\n",
        "  init_random_state(Gs, 10)\r\n",
        "  z = seed2vec(Gs, i)\r\n",
        "  img = generate_image(Gs, z, 1.0)\r\n",
        "  display_image(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYxNRMBIKeOP"
      },
      "source": [
        "## Examining the Latent Vector\n",
        "\n",
        "Figure 7.LVEC shows the effects of transforming the latent vector between two images. This transformation is accomplished by moving one 512-value latent vector slowly to the other 512 vector.  Images that have similar latent vectors will appear similarly to each other.  A high-dimension point between two latent vectos will appear similar to both of the two endpoint latent vectors.\n",
        "\n",
        "**Figure 7.LVEC: Transforming the Latent Vector**\n",
        "![GAN](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/gan_progression.jpg \"GAN\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmcC3fd43kqC"
      },
      "source": [
        "# sc = dnnlib.SubmitConfig()\r\n",
        "# sc.num_gpus = 1\r\n",
        "# sc.submit_target = dnnlib.SubmitTarget.LOCAL\r\n",
        "# sc.local.do_not_copy_source_files = True\r\n",
        "# sc.run_dir_root = \"/content/drive/My Drive/projects/stylegan2\"\r\n",
        "# sc.run_desc = 'generate-images'\r\n",
        "# network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'\r\n",
        "\r\n",
        "# print('Loading networks from \"%s\"...' % network_pkl)\r\n",
        "# _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\r\n",
        "# vector_size = Gs.input_shape[1:][0]\r\n",
        "# # range(8192,8300)\r\n",
        "# seeds = expand_seed( [8192+1,8192+9], vector_size)\r\n",
        "# #generate_images(Gs, seeds,truncation_psi=0.5)\r\n",
        "# print(seeds[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUR6JWQe4Ko3"
      },
      "source": [
        "The following code will move between the provided seeds. The constant STEPS specify how many frames there should be between each of the seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621,
          "referenced_widgets": [
            "5d2b9009445846f9a4ab7de845d2721f",
            "f26710e2d35e4584990a65466e35ea30",
            "c0e61e20b2da448a946c62516ab6169d",
            "e57a2506487a42e68d14cb954184556c",
            "fd7c425ec6b04d888f74581161de04f1",
            "54716bde643b43adbe80a8cae0b5b1cc",
            "e2b2fe2cb5d8432fbaee6df1ff293a8e",
            "46e9015c7bda4079bc7779bd8aeeaa51",
            "6652e56ccb644972bfc561d1d66ac96f",
            "8cb0387b6adb4b909feecba7df8de4fa",
            "0db9168525c449ada302a5b322fdf2c7",
            "7a690864aaaa458cba99bfa74e8aa688",
            "a00f7a43aa194e2e8e07b4256f71c959",
            "549ce442b2034d0db29e6b58a4e591c2",
            "274c867186be4d75bfb9f6d838eeacd5",
            "aa7bc07ebdf14c96bc3a1595e08a2b92"
          ]
        },
        "id": "TkO-w4us3bPg",
        "outputId": "1edf349c-19e1-4473-e938-c58d027037b4"
      },
      "source": [
        "# Choose your seeds to morph through and the number of steps to take to get to each.\r\n",
        "\r\n",
        "SEEDS = [1000,1003,1001]\r\n",
        "STEPS = 100\r\n",
        "\r\n",
        "# Remove any prior results\r\n",
        "!rm /content/results/* \r\n",
        "\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "\r\n",
        "os.makedirs(\"./results/\", exist_ok=True)\r\n",
        "\r\n",
        "# Generate the images for the video.\r\n",
        "idx = 0\r\n",
        "for i in range(len(SEEDS)-1):\r\n",
        "  v1 = seed2vec(Gs, SEEDS[i])\r\n",
        "  v2 = seed2vec(Gs, SEEDS[i+1])\r\n",
        "\r\n",
        "  diff = v2 - v1\r\n",
        "  step = diff / STEPS\r\n",
        "  current = v1.copy()\r\n",
        "\r\n",
        "  for j in tqdm(range(STEPS), desc=f\"Seed {SEEDS[i]}\"):\r\n",
        "    current = current + step\r\n",
        "    init_random_state(Gs, 10)\r\n",
        "    img = generate_image(Gs, current, 1.0)\r\n",
        "    PIL.Image.fromarray(img, 'RGB').save(f'./results/frame-{idx}.png')\r\n",
        "    idx+=1\r\n",
        " \r\n",
        "# Link the images into a video.\r\n",
        "!ffmpeg -r 30 -i /content/results/frame-%d.png -vcodec mpeg4 -y movief.mp4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d2b9009445846f9a4ab7de845d2721f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Seed 1000', style=ProgressStyle(description_width='initiaâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6652e56ccb644972bfc561d1d66ac96f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Seed 1003', style=ProgressStyle(description_width='initiaâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from '/content/results/frame-%d.png':\n",
            "  Duration: 00:00:08.00, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 1024x1024, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> mpeg4 (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp4, to 'movief.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: mpeg4 (mp4v / 0x7634706D), yuv420p, 1024x1024, q=2-31, 200 kb/s, 30 fps, 15360 tbn, 30 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 mpeg4\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
            "frame=  200 fps= 45 q=31.0 Lsize=    1417kB time=00:00:06.63 bitrate=1749.4kbits/s speed=1.48x    \n",
            "video:1415kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.120235%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCDuB56p4ZmA"
      },
      "source": [
        "Download the generated video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QLQ7z-V84bTp",
        "outputId": "bb03fead-a033-46a7-ba9f-234a5c1e6d35"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.download('movief.mp4')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e6363955-284d-49b8-8a71-fdbcb70e676f\", \"movief.mp4\", 1450573)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}